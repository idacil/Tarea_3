{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3bfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb019bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81503733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hacen entontonces esas respectivas listas con nuevos nombres\n",
    "(x_train, y_train), (x_test, y_test) = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4411d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se transforma cada una de las listas en una \"imagen aplanada\", en un vector\n",
    "#se usa el comando \"nombre\".reshape(\"num de imagenes\", \"tamaño del vector\")\n",
    "x_trainv = x_train.reshape(60000, 784)\n",
    "x_testv = x_test.reshape(10000, 784)\n",
    "\n",
    "#Aquí se convierten a números de punto flotante 32 dígitos \n",
    "x_trainv = x_trainv.astype('float32')\n",
    "x_testv = x_testv.astype('float32')\n",
    "\n",
    "#ahora es posible normarlizarlos para obtener solo números del 0 al 1\n",
    "x_trainv /= 255  \n",
    "x_testv /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041b54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crean las 10 clases distintas posibles a obtener (0,1,2,3,4,5,6,7,8,9)\n",
    "num_classes = 10\n",
    "\n",
    "#Se le asigna un \"vector binario\" a cada clase para los los datos y de train y test\n",
    "y_trainc = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_testc = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f06a3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 600)               471000    \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 500)               300500    \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 600)               300600    \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                6010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1078110 (4.11 MB)\n",
      "Trainable params: 1078110 (4.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Aquí coloco algunos parámetros importantes\n",
    "learning_rate = 0.0001\n",
    "epochs = 30\n",
    "batch_size = 120\n",
    "\n",
    "\n",
    "#AQUÍ SE IMPLEMENTA LA RED NEURONAL, EL MODELO\n",
    "\n",
    "#El modelo que se usará será secuencial, en capas apiladas una tras otra\n",
    "model = Sequential()\n",
    "\n",
    "#1ra Capa\n",
    "model.add(Dense(600, activation='relu', input_shape=(784,)))\n",
    "\n",
    "#2da Capa\n",
    "model.add(Dense(500, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "#3ra Capa\n",
    "model.add(Dense(600, activation='relu', input_shape=(784,)))\n",
    "\n",
    "\n",
    "#4ta Capa\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#Imprimimos un resumen de la red que se está usando\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ad69560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.7023 - accuracy: 0.8167 - val_loss: 0.2885 - val_accuracy: 0.9156\n",
      "Epoch 2/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.2459 - accuracy: 0.9288 - val_loss: 0.2049 - val_accuracy: 0.9382\n",
      "Epoch 3/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1859 - accuracy: 0.9455 - val_loss: 0.1618 - val_accuracy: 0.9514\n",
      "Epoch 4/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1471 - accuracy: 0.9572 - val_loss: 0.1345 - val_accuracy: 0.9582\n",
      "Epoch 5/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1216 - accuracy: 0.9639 - val_loss: 0.1198 - val_accuracy: 0.9632\n",
      "Epoch 6/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.1027 - accuracy: 0.9693 - val_loss: 0.1114 - val_accuracy: 0.9657\n",
      "Epoch 7/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0873 - accuracy: 0.9739 - val_loss: 0.0973 - val_accuracy: 0.9692\n",
      "Epoch 8/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0756 - accuracy: 0.9774 - val_loss: 0.0942 - val_accuracy: 0.9708\n",
      "Epoch 9/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0652 - accuracy: 0.9801 - val_loss: 0.0873 - val_accuracy: 0.9735\n",
      "Epoch 10/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.0866 - val_accuracy: 0.9736\n",
      "Epoch 11/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0502 - accuracy: 0.9853 - val_loss: 0.0803 - val_accuracy: 0.9751\n",
      "Epoch 12/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0431 - accuracy: 0.9873 - val_loss: 0.0741 - val_accuracy: 0.9777\n",
      "Epoch 13/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0377 - accuracy: 0.9891 - val_loss: 0.0742 - val_accuracy: 0.9766\n",
      "Epoch 14/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0759 - val_accuracy: 0.9763\n",
      "Epoch 15/30\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0711 - val_accuracy: 0.9793\n",
      "Epoch 16/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0729 - val_accuracy: 0.9792\n",
      "Epoch 17/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.0718 - val_accuracy: 0.9795\n",
      "Epoch 18/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0172 - accuracy: 0.9956 - val_loss: 0.0720 - val_accuracy: 0.9798\n",
      "Epoch 19/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0812 - val_accuracy: 0.9777\n",
      "Epoch 20/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0734 - val_accuracy: 0.9789\n",
      "Epoch 21/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0775 - val_accuracy: 0.9788\n",
      "Epoch 22/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0752 - val_accuracy: 0.9796\n",
      "Epoch 23/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0801 - val_accuracy: 0.9791\n",
      "Epoch 24/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0851 - val_accuracy: 0.9783\n",
      "Epoch 25/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0810 - val_accuracy: 0.9790\n",
      "Epoch 26/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0793 - val_accuracy: 0.9809\n",
      "Epoch 27/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0912 - val_accuracy: 0.9780\n",
      "Epoch 28/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0864 - val_accuracy: 0.9798\n",
      "Epoch 29/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0916 - val_accuracy: 0.9777\n",
      "Epoch 30/30\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.0936 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "#Model.compile se utiliza para configurar la etapa de compilación de un modelo de red neuronal antes de entrenarlo.\n",
    "#Se coloca la función de costo, categorical_crossentropy para más de 2 clases o binary_crossentropy para 2 clases\n",
    "#Se coloca el optimizador, SGD, Adam, RSProp con su tasa de aprendizaje ya definida\n",
    "#Las métricas son medidas que se utilizan para evaluar el rendimiento del modelo durante el entrenamiento y la evaluación. \n",
    "#Puedes especificar una lista de métricas que deseas calcular, como precisión ('accuracy') o pérdida ('loss'). \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(learning_rate=learning_rate),metrics=['accuracy'])\n",
    "\n",
    "#Aquí entrenamos ya a la red, insertamos el vector de entrenamiento de cada imagen con su resultado y de entrenamiento \n",
    "#Colocamos el tamaño del minibatch\n",
    "#El número de épocas\n",
    "#Si se mostrará el progreso o no\n",
    "#Por último los datos de prueba, las entradas y salida para verificar la eficiencia etc.\n",
    "history = model.fit(x_trainv, y_trainc,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_testv, y_testc)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88e8c646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9797\n",
      "eficiencia: [0.09358642995357513, 0.9797000288963318]\n"
     ]
    }
   ],
   "source": [
    "#Se evalua la eficiencia del modelo\n",
    "score = model.evaluate(x_testv, y_testc, verbose=1) \n",
    "print(\"eficiencia:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428df08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
